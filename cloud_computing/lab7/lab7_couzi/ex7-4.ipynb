{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d6e3f03-c690-461b-97d6-56c748f160e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------+-------------------+-----------------------+-------------------+\n",
      "|Station Name               |day       |Min Solar radiation|Average Solar radiation|Max Solar radiation|\n",
      "+---------------------------+----------+-------------------+-----------------------+-------------------+\n",
      "|63rd Street Weather Station|05/06/2023|544                |544.0                  |544                |\n",
      "|Foster Weather Station     |08/11/2020|394                |504.15384615384613     |821                |\n",
      "|63rd Street Weather Station|05/19/2016|3                  |470.64285714285717     |910                |\n",
      "|Foster Weather Station     |08/12/2020|410                |463.0                  |819                |\n",
      "|Oak Street Weather Station |07/07/2018|-3                 |454.25                 |892                |\n",
      "|Oak Street Weather Station |05/21/2016|0                  |436.6                  |861                |\n",
      "|Oak Street Weather Station |05/19/2016|0                  |435.72727272727275     |900                |\n",
      "|Oak Street Weather Station |05/27/2018|-6                 |427.53333333333336     |835                |\n",
      "|63rd Street Weather Station|05/21/2016|2                  |424.7142857142857      |863                |\n",
      "|Foster Weather Station     |05/28/2015|0                  |417.0769230769231      |836                |\n",
      "+---------------------------+----------+-------------------+-----------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sparkFun\n",
    "\n",
    "#Set a name for the application\n",
    "appName = \"DataFrame Example\"\n",
    "\n",
    "#Set the input folder location\n",
    "input_folder = \"data/in\" \n",
    "\n",
    "#Set the output folder location\n",
    "output_folder = \"data/out\" \n",
    "\n",
    "#create a new Spark application and get the Spark session object\n",
    "spark = SparkSession.builder.appName(appName).getOrCreate()\n",
    "\n",
    "#read in the CSV dataset as a DataFrame\n",
    "#inferSchema option forces Spark to automatically specify data column types\n",
    "#header option forces Spark to automatically fetch column names from the first line in the dataset files\n",
    "weather_df = spark.read \\\n",
    "              .option(\"inferSchema\", True) \\\n",
    "              .option(\"header\", True) \\\n",
    "              .csv(input_folder)\n",
    "\n",
    "\n",
    "#Show 10 rows without truncating lines.\n",
    "#review content might be a multi-line string.\n",
    "#weather_df.show(10, False)\n",
    "\n",
    "#Show dataset schema/structure with filed names and types\n",
    "#weather_df.printSchema()\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "result_df = weather_df.select(\"Station Name\", \"Measurement Timestamp\", \"Solar Radiation\") \\\n",
    "                            .withColumn(\"day\", sparkFun.split(weather_df[\"Measurement Timestamp\"], \" \")[0]) \\\n",
    "                            .groupBy(\"Station Name\", \"day\") \\\n",
    "                            .agg(sparkFun.min(\"Solar Radiation\").alias(\"Min Solar radiation\"), \\\n",
    "                                 sparkFun.avg(\"Solar Radiation\").alias(\"Average Solar radiation\"), \\\n",
    "                                 sparkFun.max(\"Solar Radiation\").alias(\"Max Solar radiation\")) \\\n",
    "                            .orderBy(\"Average Solar Radiation\", ascending=False)\n",
    "\n",
    "result_df.show(10, False) \n",
    "\n",
    "result_df.coalesce(1).write.mode(\"overwrite\").format(\"csv\").save(output_folder+\"/ex7-4\")\n",
    "\n",
    "#Stop Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
